{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c5717d",
   "metadata": {},
   "source": [
    "# :basketball: 3 - Train augmentation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88cfe1f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ca2de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37d32c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae1d31b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabfccdb",
   "metadata": {},
   "source": [
    "## Predefined variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef10f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_GEOMETRIC_PATH = \"../data/basketball.yolov8-augmented/geometric/data.yaml\"\n",
    "YAML_COLOR_PATH = \"../data/basketball.yolov8-augmented/color/data.yaml\"\n",
    "YAML_KERNEL_PATH = \"../data/basketball.yolov8-augmented/kernel/data.yaml\"\n",
    "RESULTS_DIR = \"../results/\"\n",
    "MEDIA_DIR = \"../media/\"\n",
    "\n",
    "AUG_YAML_PATHS = {\n",
    "    \"geometric\": YAML_GEOMETRIC_PATH,\n",
    "    \"color\": YAML_COLOR_PATH,\n",
    "    \"kernel\": YAML_KERNEL_PATH\n",
    "}\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "RUNS_DIR = PROJECT_ROOT / \"runs\" / \"augmented\"\n",
    "\n",
    "Path(RUNS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "EPOCHS = 100\n",
    "IMG_SIZE = 640\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "PALETTE = \"flare\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72662187",
   "metadata": {},
   "source": [
    "## Train augmented datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a206e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate(dataset_name, yaml_path):\n",
    "    print(f\"Training YOLOv8n on {dataset_name} augmented dataset...\")\n",
    "\n",
    "    # Clear CUDA cache\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Define run names\n",
    "    train_name = f\"yolov8n-{dataset_name}-train\"\n",
    "    valid_name = f\"yolov8n-{dataset_name}-valid\"\n",
    "\n",
    "    # Load YOLOV8n model\n",
    "    yolov8 = YOLO(\"yolov8n.pt\", \"detect\").to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Train the model\n",
    "    yolov8.train(\n",
    "        data=yaml_path,\n",
    "        epochs=EPOCHS,\n",
    "        imgsz=IMG_SIZE,\n",
    "        batch=BATCH_SIZE,\n",
    "        project=str(RUNS_DIR),\n",
    "        name=train_name,\n",
    "        augment=False,\n",
    "        exist_ok=False,\n",
    "        seed=42,\n",
    "        workers=0 # Set workers to 0 for compatibility and reduce overhead\n",
    "    )\n",
    "\n",
    "    # Clear CUDA cache\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Evaluate the model on test set\n",
    "    metrics = yolov8.val(data=yaml_path, project=str(RUNS_DIR), name=valid_name, split=\"test\", exist_ok=False)\n",
    "    print(f\"Evaluation metrics for {dataset_name} augmented dataset: {metrics}\")\n",
    "\n",
    "    # Clear CUDA cache\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Return the evaluation metrics for further use\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03a57cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training YOLOv8n on geometric augmented dataset...\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/basketball.yolov8-augmented/geometric/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n-geometric-train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=c:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-geometric-train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753067  ultralytics.nn.modules.head.Detect           [9, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,012,603 parameters, 3,012,587 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 624.7585.5 MB/s, size: 82.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\data\\basketball.yolov8-augmented\\geometric\\train\\labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 240/240  0.0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 624.2416.7 MB/s, size: 56.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\data\\basketball.yolov8-augmented\\geometric\\valid\\labels.cache... 25 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 25/25  0.0s\n",
      "Plotting labels to C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-geometric-train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-geometric-train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100      2.54G      1.854      4.157      1.407        259        640: 100% ━━━━━━━━━━━━ 15/15 2.6it/s 5.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.4it/s 0.7s\n",
      "                   all         25        361     0.0139     0.0609     0.0142    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100      2.55G        1.8      2.657      1.283        380        640: 100% ━━━━━━━━━━━━ 15/15 3.1it/s 4.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361     0.0236      0.119     0.0766     0.0407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100      2.56G      1.662      2.085      1.201        365        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361     0.0225      0.153      0.091     0.0522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100      2.56G      1.625      1.918      1.217        418        640: 100% ━━━━━━━━━━━━ 15/15 3.1it/s 4.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
      "                   all         25        361     0.0262      0.226      0.101     0.0569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100      2.56G      1.605      1.772      1.189        393        640: 100% ━━━━━━━━━━━━ 15/15 2.8it/s 5.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.3s\n",
      "                   all         25        361      0.712      0.149      0.181     0.0971\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100      2.56G      1.597      1.757      1.202        395        640: 100% ━━━━━━━━━━━━ 15/15 2.8it/s 5.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361      0.651       0.21        0.2      0.116\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100      2.56G      1.546      1.626      1.195        237        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.3s\n",
      "                   all         25        361      0.652      0.265      0.261      0.149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100      2.56G      1.492      1.517      1.172        352        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.491      0.283      0.313      0.178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100      2.56G      1.526      1.444      1.185        480        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361       0.56      0.292      0.382      0.215\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100      2.56G      1.533        1.4      1.171        324        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.435      0.371      0.423      0.242\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/100      2.56G      1.555       1.41      1.151        389        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.454      0.474      0.483      0.279\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/100      2.56G      1.478      1.376      1.127        259        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.486      0.466      0.535      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/100      2.56G      1.466      1.368      1.184        308        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361      0.501      0.539      0.552       0.29\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/100      2.56G      1.376      1.233      1.105        274        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.791       0.43       0.56      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/100      2.56G      1.374      1.174      1.086        277        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.508      0.541      0.566      0.343\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/100      2.56G      1.366      1.151      1.099        299        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.685      0.535      0.593      0.366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/100      2.56G      1.339       1.13      1.089        306        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.776      0.496       0.61      0.381\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/100      2.56G      1.313      1.087       1.08        383        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.628      0.588      0.648      0.392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/100      2.56G      1.364      1.127      1.088        331        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.657      0.655      0.665      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/100      2.56G       1.33      1.085      1.075        331        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.666      0.586      0.673      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/100      2.56G      1.294      1.073      1.077        400        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.636      0.664      0.663      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/100      2.56G        1.3      1.059      1.077        383        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.683      0.673      0.692      0.434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/100      2.56G      1.251      1.001      1.041        430        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.694      0.663      0.672      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/100      2.56G      1.292      1.016      1.064        246        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.705      0.674      0.705      0.431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/100      2.56G      1.245     0.9823      1.054        255        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.696      0.702      0.724      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/100      2.56G      1.222      0.954      1.038        266        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.727      0.731      0.735      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/100      2.56G      1.252     0.9649      1.044        339        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.712      0.718      0.723      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/100      2.56G      1.267     0.9664      1.062        378        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
      "                   all         25        361      0.739      0.684      0.717      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/100      2.56G      1.231     0.9741      1.033        274        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.717      0.721       0.72      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/100      2.56G      1.212     0.9313      1.035        286        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.724      0.711      0.716      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/100      2.56G      1.162      0.895      1.016        366        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.728      0.729      0.737      0.478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/100      2.56G      1.211     0.9162      1.032        346        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.712      0.703      0.741       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/100      2.56G      1.224     0.8951      1.021        258        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.743      0.719      0.754      0.485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/100      2.56G      1.214     0.8911      1.028        416        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.718      0.704      0.764       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/100      2.56G      1.195     0.8866      1.033        311        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.762      0.721       0.76      0.471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/100      2.56G      1.209     0.8814       1.02        405        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361       0.74      0.721      0.751      0.483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/100      2.56G      1.227      0.891      1.036        328        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361      0.714      0.749      0.764      0.487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/100      2.56G      1.151     0.8669      1.016        236        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.791      0.693       0.75      0.483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/100      2.56G      1.155     0.8672      1.003        368        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.781      0.692      0.767      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/100      2.56G       1.13     0.8316     0.9973        319        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361       0.75      0.701      0.768      0.496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/100      2.56G      1.133     0.8249      1.008        355        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.718       0.73      0.765      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/100      2.56G       1.14     0.8347      1.004        248        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.772      0.707      0.764      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/100      2.56G      1.167     0.8464       1.02        425        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.1it/s 0.2s\n",
      "                   all         25        361      0.756      0.734       0.78      0.471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     44/100      2.56G      1.192     0.8448      1.021        344        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.757      0.754      0.771      0.488\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     45/100      2.56G      1.162     0.8282     0.9976        404        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.782      0.756      0.781      0.487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     46/100      2.56G      1.155     0.8211      1.001        258        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.3it/s 0.2s\n",
      "                   all         25        361      0.766      0.757      0.779      0.493\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     47/100      2.56G      1.143     0.8322      1.007        414        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361       0.82      0.728      0.772      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     48/100      2.56G      1.127     0.8047      1.004        288        640: 100% ━━━━━━━━━━━━ 15/15 3.8it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.3it/s 0.2s\n",
      "                   all         25        361      0.822      0.712       0.78      0.487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     49/100      2.56G      1.114     0.7935     0.9931        349        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.825      0.716      0.772      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     50/100      2.56G      1.101     0.7994     0.9838        376        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.758      0.766      0.778        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     51/100      2.56G      1.108     0.7869     0.9877        276        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.799      0.722      0.774      0.485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     52/100      2.56G      1.089     0.7706     0.9786        367        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361       0.77      0.756      0.781      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     53/100      2.56G      1.086       0.77      0.976        299        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.799       0.72      0.792      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     54/100      2.56G      1.068     0.7522     0.9774        354        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.769      0.741       0.79      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     55/100      2.56G      1.062     0.7463     0.9769        397        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.786      0.751       0.79      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     56/100      2.56G      1.102     0.7441     0.9672        364        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.815      0.725      0.786      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     57/100      2.56G      1.085     0.7708     0.9844        400        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361       0.77      0.781      0.797      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     58/100      2.56G      1.093     0.7567     0.9824        381        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.741      0.804      0.804        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     59/100      2.56G      1.089     0.7565     0.9863        362        640: 100% ━━━━━━━━━━━━ 15/15 3.8it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.2it/s 0.2s\n",
      "                   all         25        361      0.754      0.775      0.821      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     60/100      2.72G      1.051     0.7366     0.9682        327        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.2it/s 0.2s\n",
      "                   all         25        361      0.804      0.777        0.8      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     61/100      2.72G      1.025     0.7299     0.9663        319        640: 100% ━━━━━━━━━━━━ 15/15 3.8it/s 3.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.798      0.786      0.812      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     62/100      2.72G      1.038     0.7179     0.9688        240        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.797      0.785      0.826      0.516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     63/100      2.72G      1.034     0.7316     0.9618        336        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361       0.79      0.781      0.812       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     64/100      2.72G      1.028     0.7254     0.9747        249        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.772      0.814      0.809      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     65/100      2.72G      1.038     0.7114     0.9683        294        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361      0.747      0.803      0.819      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     66/100      2.72G     0.9976     0.6905     0.9535        349        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.814      0.769      0.811      0.516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     67/100      2.72G      1.005     0.6939     0.9511        346        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361      0.826      0.798      0.834      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     68/100      2.72G      1.001     0.6948     0.9521        289        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361      0.852      0.779      0.835      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     69/100      2.72G     0.9845      0.698     0.9611        292        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.852      0.755      0.837      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     70/100      2.72G     0.9841     0.6888     0.9549        295        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.833      0.778      0.831      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     71/100      2.72G      1.003     0.6861      0.946        291        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361      0.848      0.788      0.833      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     72/100      2.72G      1.003     0.6905     0.9485        327        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
      "                   all         25        361      0.804       0.81      0.828       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     73/100      2.72G     0.9717     0.6794     0.9524        336        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361       0.81      0.791      0.828      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     74/100      2.72G      0.986     0.6869      0.949        321        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.815      0.785      0.828      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     75/100      2.72G     0.9834     0.6784     0.9453        191        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.784      0.797      0.822      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     76/100      2.72G      0.992     0.7004     0.9515        486        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361      0.807      0.799      0.825      0.517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     77/100      2.72G     0.9976      0.686      0.953        392        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.813      0.798      0.833      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     78/100      2.72G     0.9716     0.6692     0.9401        325        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.818      0.776      0.826      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     79/100      2.72G     0.9527     0.6613     0.9397        244        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
      "                   all         25        361      0.783      0.787      0.827      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     80/100      2.72G     0.9548     0.6537     0.9338        453        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.1it/s 0.2s\n",
      "                   all         25        361      0.826      0.762       0.82      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     81/100      2.72G     0.9713     0.6736     0.9409        306        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.826      0.784      0.828      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     82/100      2.72G     0.9691     0.6734     0.9396        362        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.824      0.781      0.832      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     83/100      2.72G     0.9717     0.6713     0.9446        271        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.808      0.802      0.834      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     84/100      2.72G     0.9494     0.6512     0.9319        306        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
      "                   all         25        361      0.831      0.798      0.832      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     85/100      2.72G     0.9393     0.6441     0.9309        297        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.827      0.788      0.837      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     86/100      2.72G     0.9419     0.6468     0.9397        266        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.847      0.793      0.845      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     87/100      2.72G     0.9461     0.6494     0.9385        366        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.854       0.79      0.845      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     88/100      2.72G     0.9428     0.6415     0.9315        418        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.859      0.799      0.848      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     89/100      2.72G      0.923      0.636     0.9234        429        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361      0.856      0.804      0.846      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     90/100      2.72G     0.9603     0.6531     0.9416        316        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
      "                   all         25        361      0.866      0.779      0.842      0.547\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     91/100      2.72G     0.8407      0.591     0.9007        200        640: 100% ━━━━━━━━━━━━ 15/15 2.7it/s 5.5s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5it/s 0.4s\n",
      "                   all         25        361       0.86      0.785       0.84      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     92/100      2.72G     0.8389      0.576     0.8968        238        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.827      0.784      0.842      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     93/100      2.72G     0.8218      0.561     0.8881        257        640: 100% ━━━━━━━━━━━━ 15/15 3.9it/s 3.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
      "                   all         25        361      0.831      0.779      0.843      0.538\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     94/100      2.72G     0.8244      0.569     0.8877        216        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
      "                   all         25        361      0.797      0.838      0.847      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     95/100      2.72G      0.819     0.5643     0.8925        230        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.816      0.824      0.846      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     96/100      2.72G     0.8242     0.5646      0.894        227        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361       0.83      0.813      0.845      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     97/100      2.72G     0.8115      0.553     0.8876        211        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.824      0.823      0.843      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     98/100      2.72G      0.832     0.5694     0.8953        219        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
      "                   all         25        361      0.838      0.813      0.844      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     99/100      2.72G     0.8078     0.5561     0.8949        218        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.831      0.788      0.841       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    100/100      2.72G     0.7998     0.5523     0.8863        216        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.841      0.786      0.841      0.532\n",
      "\n",
      "100 epochs completed in 0.132 hours.\n",
      "Optimizer stripped from C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-geometric-train\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-geometric-train\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-geometric-train\\weights\\best.pt...\n",
      "Ultralytics 8.3.252  Python-3.12.0 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,007,403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
      "                   all         25        361      0.859      0.799      0.848      0.551\n",
      "                  Ball         13         13      0.776      0.308      0.397      0.208\n",
      "                  Hoop         17         17        0.8          1      0.938      0.637\n",
      "                Period         17         18      0.923      0.666      0.838      0.556\n",
      "                Player         24        188      0.872      0.836      0.908      0.577\n",
      "                   Ref         21         43      0.876      0.824      0.882      0.589\n",
      "            Shot Clock         14         14      0.884      0.929      0.964      0.579\n",
      "             Team Name          8         16      0.811      0.805       0.86      0.518\n",
      "           Team Points         17         35      0.852      0.914      0.922      0.658\n",
      "        Time Remaining         17         17      0.939      0.908      0.921      0.641\n",
      "Speed: 0.2ms preprocess, 1.8ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-geometric-train\u001b[0m\n",
      "Ultralytics 8.3.252  Python-3.12.0 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,007,403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 2.40.8 MB/s, size: 47.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\data\\basketball.yolov8-augmented\\geometric\\test\\labels.cache... 25 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 25/25  0.0s\n",
      "WARNING Box and segment counts should be equal, but got len(segments) = 15, len(boxes) = 391. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.7s/it 3.3s9.6s\n",
      "                   all         25        391      0.883      0.756      0.818       0.51\n",
      "                  Ball         20         20      0.782        0.2      0.326      0.195\n",
      "                  Hoop         18         18      0.862      0.833      0.885      0.585\n",
      "                Period         19         19      0.942      0.851      0.974      0.548\n",
      "                Player         25        201      0.898      0.835      0.856      0.574\n",
      "                   Ref         22         47       0.86      0.781      0.783      0.501\n",
      "            Shot Clock         18         18      0.982      0.722      0.839      0.425\n",
      "             Team Name          6         12       0.83      0.917      0.842      0.578\n",
      "           Team Points         19         38      0.793      0.905      0.911      0.606\n",
      "        Time Remaining         18         18          1      0.761      0.941      0.577\n",
      "Speed: 6.6ms preprocess, 21.2ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-geometric-valid\u001b[0m\n",
      "Evaluation metrics for geometric augmented dataset: ultralytics.utils.metrics.DetMetrics object with attributes:\n",
      "\n",
      "ap_class_index: array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "box: ultralytics.utils.metrics.Metric object\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000022C5EE54EC0>\n",
      "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
      "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,  0.00010735,  5.3673e-05,           0],\n",
      "       [          1,           1,           1, ...,   0.0015628,  0.00078139,           0],\n",
      "       [          1,           1,           1, ...,     0.73077,     0.73077,           0],\n",
      "       ...,\n",
      "       [    0.91667,     0.91667,     0.91667, ...,     0.04461,     0.04461,           0],\n",
      "       [          1,           1,           1, ...,      0.6129,      0.6129,           0],\n",
      "       [          1,           1,           1, ...,     0.48649,     0.48649,           0]], shape=(9, 1000)), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.050891,    0.050891,     0.10166, ...,           0,           0,           0],\n",
      "       [   0.082927,    0.082927,     0.15705, ...,           0,           0,           0],\n",
      "       [    0.12298,     0.12298,      0.1893, ...,           0,           0,           0],\n",
      "       ...,\n",
      "       [    0.07767,     0.07767,     0.10268, ...,           0,           0,           0],\n",
      "       [    0.19192,     0.19192,     0.26946, ...,           0,           0,           0],\n",
      "       [    0.12121,     0.12121,     0.17559, ...,           0,           0,           0]], shape=(9, 1000)), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.02681,     0.02681,    0.056581, ...,           1,           1,           1],\n",
      "       [   0.043367,    0.043367,    0.085644, ...,           1,           1,           1],\n",
      "       [   0.065517,    0.065517,     0.10454, ...,           1,           1,           1],\n",
      "       ...,\n",
      "       [   0.040404,    0.040404,    0.054386, ...,           1,           1,           1],\n",
      "       [    0.10615,     0.10615,     0.15571, ...,           1,           1,           1],\n",
      "       [   0.064516,    0.064516,    0.096242, ...,           1,           1,           1]], shape=(9, 1000)), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[        0.5,         0.5,         0.5, ...,           0,           0,           0],\n",
      "       [    0.94444,     0.94444,     0.94444, ...,           0,           0,           0],\n",
      "       [          1,           1,           1, ...,           0,           0,           0],\n",
      "       ...,\n",
      "       [          1,           1,     0.91667, ...,           0,           0,           0],\n",
      "       [          1,           1,           1, ...,           0,           0,           0],\n",
      "       [          1,           1,           1, ...,           0,           0,           0]], shape=(9, 1000)), 'Confidence', 'Recall']]\n",
      "fitness: np.float64(0.5098712409639873)\n",
      "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
      "maps: array([    0.19503,     0.58473,      0.5485,     0.57378,     0.50095,     0.42458,     0.57807,     0.60616,     0.57703])\n",
      "names: {0: 'Ball', 1: 'Hoop', 2: 'Period', 3: 'Player', 4: 'Ref', 5: 'Shot Clock', 6: 'Team Name', 7: 'Team Points', 8: 'Time Remaining'}\n",
      "nt_per_class: array([ 20,  18,  19, 201,  47,  18,  12,  38,  18])\n",
      "nt_per_image: array([20, 18, 19, 25, 22, 18,  6, 19, 18])\n",
      "results_dict: {'metrics/precision(B)': 0.8830519595354729, 'metrics/recall(B)': 0.7561423151727789, 'metrics/mAP50(B)': 0.8175004022566905, 'metrics/mAP50-95(B)': 0.5098712409639873, 'fitness': 0.5098712409639873}\n",
      "save_dir: WindowsPath('C:/Users/kyana/Documents/GitHub/data-augmentation-detection-basketball/runs/augmented/yolov8n-geometric-valid')\n",
      "speed: {'preprocess': 6.580291999998735, 'inference': 21.202827999950387, 'loss': 0.0006880000000819564, 'postprocess': 2.6280719999340363}\n",
      "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
      "task: 'detect'\n",
      "Training YOLOv8n on color augmented dataset...\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/basketball.yolov8-augmented/color/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n-color-train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=c:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-color-train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753067  ultralytics.nn.modules.head.Detect           [9, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,012,603 parameters, 3,012,587 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 159.244.8 MB/s, size: 81.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\data\\basketball.yolov8-augmented\\color\\train\\labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 240/240  0.0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 8.80.9 MB/s, size: 56.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\data\\basketball.yolov8-augmented\\color\\valid\\labels.cache... 25 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 25/25  0.0s\n",
      "Plotting labels to C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-color-train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-color-train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100      2.77G      1.761      4.156      1.352        269        640: 100% ━━━━━━━━━━━━ 15/15 2.8it/s 5.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.5it/s 0.7s\n",
      "                   all         25        361     0.0131     0.0532     0.0117    0.00517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100      2.78G      1.701      2.603       1.22        382        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361     0.0263      0.139      0.082     0.0441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100      2.78G      1.598       2.05      1.169        369        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.3s\n",
      "                   all         25        361     0.0255      0.157     0.0916     0.0527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100      2.78G      1.529      1.864      1.168        412        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.027      0.181     0.0899     0.0517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100      2.78G      1.525      1.732       1.15        404        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
      "                   all         25        361      0.792      0.123      0.165     0.0985\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100      2.78G      1.525      1.701       1.16        386        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361      0.754      0.128      0.209      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100      2.78G      1.486      1.567      1.157        227        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
      "                   all         25        361      0.534      0.187      0.243      0.144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100      2.79G      1.432      1.478      1.142        355        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361      0.451       0.27      0.325      0.194\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100      2.79G      1.431      1.368       1.14        465        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
      "                   all         25        361      0.474      0.336      0.388      0.242\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100      2.79G      1.383      1.293      1.106        329        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361       0.48       0.35      0.433      0.256\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/100      2.79G      1.336      1.238      1.079        389        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
      "                   all         25        361      0.719      0.408      0.501      0.292\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/100      2.79G       1.35      1.218      1.077        263        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
      "                   all         25        361      0.535      0.522      0.546      0.329\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/100      2.79G      1.327      1.238      1.091        291        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8it/s 0.3s\n",
      "                   all         25        361      0.627      0.558      0.554      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/100      2.79G      1.299      1.141      1.066        273        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8it/s 0.3s\n",
      "                   all         25        361      0.589      0.497      0.585      0.351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/100      2.79G      1.293       1.12      1.054        292        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
      "                   all         25        361      0.638      0.595      0.608       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/100      2.79G      1.281      1.099      1.057        282        640: 100% ━━━━━━━━━━━━ 15/15 3.1it/s 4.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
      "                   all         25        361      0.654      0.554      0.629      0.399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/100      2.79G      1.283      1.118      1.058        309        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.642       0.58      0.628       0.38\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/100      2.79G      1.258      1.039      1.042        372        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
      "                   all         25        361      0.651       0.61      0.652      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/100      2.79G       1.26      1.082      1.035        325        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.658      0.641      0.661      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/100      2.79G      1.229      1.016      1.036        360        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.615      0.654      0.673       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/100      2.79G      1.204      1.008      1.036        404        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.645      0.635      0.663      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/100      2.79G      1.198     0.9833      1.028        392        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.745      0.604      0.685      0.422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/100      2.79G      1.174     0.9406      1.009        438        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361       0.63       0.68      0.685      0.423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/100      2.79G      1.204     0.9515      1.025        254        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.619      0.682      0.693       0.44\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/100      2.79G      1.186     0.9272      1.016        265        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
      "                   all         25        361      0.683      0.697      0.717      0.446\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/100      2.79G      1.178     0.9172       1.01        255        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.741      0.702      0.726      0.442\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/100      2.79G      1.159     0.9183      1.005        335        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
      "                   all         25        361      0.773      0.591      0.688      0.421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/100      2.79G       1.17     0.9232      1.009        384        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
      "                   all         25        361      0.707      0.716      0.714      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/100      2.79G      1.157     0.9065      1.001        272        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.722      0.698      0.688      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/100      2.79G      1.121     0.8645     0.9974        289        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.722      0.719       0.72      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/100      2.79G      1.094     0.8407      0.987        366        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
      "                   all         25        361      0.763      0.707      0.748      0.473\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/100      2.79G      1.135     0.8599     0.9952        351        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361      0.681      0.733      0.749      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/100      2.79G      1.137     0.8431     0.9877        249        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.697      0.726      0.758      0.464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/100      2.95G      1.114     0.8405     0.9849        409        640: 100% ━━━━━━━━━━━━ 15/15 3.1it/s 4.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.3s\n",
      "                   all         25        361      0.804      0.643      0.746      0.453\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/100      2.95G       1.07     0.8227     0.9824        307        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361      0.702      0.757      0.759      0.469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/100      2.95G      1.097     0.8266     0.9815        394        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.801      0.782      0.786       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/100      2.95G      1.082     0.8133     0.9805        324        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.766      0.765      0.793      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/100      2.95G      1.076     0.8071     0.9798        231        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.744      0.769      0.789      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/100      2.95G      1.094     0.8361     0.9729        372        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361       0.72      0.748      0.775      0.485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/100      2.95G      1.087      0.794     0.9684        322        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.694      0.773      0.784      0.485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/100      2.95G       1.07     0.7889     0.9784        352        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.735      0.749      0.797      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/100      2.95G      1.073     0.7926     0.9708        253        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.1it/s 0.2s\n",
      "                   all         25        361      0.699      0.772      0.772      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/100      2.95G      1.064     0.7838     0.9735        413        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.749      0.738      0.782      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     44/100      2.95G       1.04     0.7635     0.9631        343        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361       0.77       0.77      0.787      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     45/100      2.95G      1.047     0.7642     0.9575        398        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.841      0.731      0.802      0.516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     46/100      2.95G      1.019      0.751     0.9582        260        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.788      0.743      0.784      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     47/100      2.95G      1.023     0.7631     0.9605        417        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361      0.807       0.75        0.8      0.516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     48/100      2.95G      1.024      0.748     0.9614        296        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.816       0.75      0.797      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     49/100      2.95G      1.034     0.7491      0.961        351        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.795      0.749      0.793      0.501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     50/100      2.95G      1.026      0.752     0.9583        387        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.841      0.746      0.795      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     51/100      2.95G      1.024       0.74     0.9547        270        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.3s\n",
      "                   all         25        361      0.823      0.776      0.807      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     52/100      2.95G      1.004     0.7267     0.9403        353        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361       0.83      0.761      0.808      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     53/100      2.95G      1.015     0.7267     0.9498        285        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.828      0.751      0.808      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     54/100      2.95G      1.011     0.7171     0.9508        368        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.844      0.752      0.798      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     55/100      2.95G     0.9915     0.7091     0.9482        401        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.851      0.729      0.805      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     56/100      2.95G      1.021      0.707     0.9387        365        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.799      0.753      0.806      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     57/100      2.95G     0.9937     0.7118     0.9518        382        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.823       0.75      0.814      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     58/100      2.95G     0.9872     0.7073     0.9468        378        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.3it/s 0.2s\n",
      "                   all         25        361      0.733      0.796      0.814      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     59/100      2.95G     0.9892     0.7045     0.9476        368        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.841      0.728      0.808      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     60/100      2.95G     0.9585     0.6761     0.9364        330        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.1it/s 0.2s\n",
      "                   all         25        361      0.843      0.714      0.797      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     61/100      2.95G     0.9498       0.68     0.9373        319        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361      0.829      0.748      0.805      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     62/100      2.95G     0.9579     0.6743     0.9397        244        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
      "                   all         25        361      0.784      0.752      0.798      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     63/100      2.95G     0.9718     0.6765     0.9332        326        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361       0.81      0.733      0.799      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     64/100      2.95G     0.9539     0.6736     0.9393        241        640: 100% ━━━━━━━━━━━━ 15/15 3.1it/s 4.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.815      0.753      0.808      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     65/100      2.95G     0.9629     0.6713     0.9355        283        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361       0.77      0.802      0.812      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     66/100      2.95G     0.9235     0.6567     0.9263        350        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.806      0.758      0.829      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     67/100      2.95G     0.9398     0.6566     0.9265        336        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.836      0.767      0.828      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     68/100      2.95G     0.9231      0.645     0.9254        278        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361       0.86      0.746      0.823      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     69/100      2.95G      0.916     0.6459     0.9363        282        640: 100% ━━━━━━━━━━━━ 15/15 3.8it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.1it/s 0.2s\n",
      "                   all         25        361      0.794      0.778      0.812      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     70/100      2.95G     0.9219     0.6516     0.9306        298        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.853      0.752      0.816       0.55\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     71/100      2.95G     0.9458     0.6572     0.9214        287        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.803      0.765      0.814      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     72/100      2.95G     0.9502     0.6597      0.926        338        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361      0.841      0.739      0.823      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     73/100      2.95G     0.9057     0.6434     0.9276        327        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.813      0.788      0.824      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     74/100      2.95G     0.8951     0.6338     0.9158        336        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.803       0.79       0.82      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     75/100      2.95G     0.9144     0.6419     0.9156        189        640: 100% ━━━━━━━━━━━━ 15/15 3.0it/s 5.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
      "                   all         25        361      0.817      0.793      0.816      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     76/100      2.95G     0.9266     0.6526     0.9242        475        640: 100% ━━━━━━━━━━━━ 15/15 3.0it/s 5.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
      "                   all         25        361      0.842      0.769      0.817      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     77/100      2.95G     0.9247     0.6446     0.9237        386        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.882      0.755      0.816      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     78/100      2.95G     0.9132      0.633     0.9171        327        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
      "                   all         25        361      0.793      0.783      0.812      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     79/100      2.95G     0.8836     0.6238     0.9147        248        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
      "                   all         25        361      0.808      0.762      0.808      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     80/100      2.95G     0.8895     0.6195     0.9093        465        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361      0.821      0.764      0.808      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     81/100      2.95G     0.8995     0.6271     0.9146        333        640: 100% ━━━━━━━━━━━━ 15/15 1.5it/s 10.3s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.3it/s 0.8s\n",
      "                   all         25        361      0.878      0.745      0.812       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     82/100      2.95G     0.8995     0.6295     0.9142        374        640: 100% ━━━━━━━━━━━━ 15/15 1.3s/it 19.0s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.2it/s 0.8s\n",
      "                   all         25        361      0.838      0.761      0.811      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     83/100      2.95G     0.8983     0.6224     0.9194        266        640: 100% ━━━━━━━━━━━━ 15/15 1.2s/it 17.8s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
      "                   all         25        361      0.826      0.774      0.816      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     84/100      2.95G     0.8791     0.6087     0.9079        293        640: 100% ━━━━━━━━━━━━ 15/15 3.8it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361      0.852      0.746      0.812      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     85/100      3.12G       0.87     0.6043     0.9067        292        640: 100% ━━━━━━━━━━━━ 15/15 3.8it/s 3.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.806      0.789      0.819      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     86/100      3.12G     0.8751     0.6053     0.9189        256        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.815      0.798      0.817      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     87/100      3.12G      0.887     0.6143     0.9181        355        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.813      0.787      0.813      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     88/100      3.12G     0.8729     0.6005     0.9066        400        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.813      0.798       0.81      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     89/100      3.28G     0.8587     0.6012     0.9024        450        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361      0.829      0.781      0.808      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     90/100      3.28G     0.8893     0.6201     0.9209        314        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.855      0.754      0.811      0.527\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     91/100      3.28G     0.7805     0.5506     0.8757        199        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.855      0.761      0.809      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     92/100      3.28G     0.7851      0.541      0.875        241        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.827      0.774      0.808      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     93/100      3.28G     0.7642      0.532     0.8702        257        640: 100% ━━━━━━━━━━━━ 15/15 3.8it/s 3.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.827      0.779      0.807      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     94/100      3.28G     0.7636     0.5369     0.8703        214        640: 100% ━━━━━━━━━━━━ 15/15 3.8it/s 3.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361       0.84      0.782       0.81      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     95/100      3.28G     0.7631     0.5352     0.8723        230        640: 100% ━━━━━━━━━━━━ 15/15 3.8it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361      0.842      0.782      0.811      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     96/100      3.28G     0.7564     0.5254     0.8729        228        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361       0.82      0.797      0.811       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     97/100      3.28G     0.7487     0.5184     0.8667        212        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.819      0.794      0.811      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     98/100      3.28G     0.7612     0.5309     0.8671        219        640: 100% ━━━━━━━━━━━━ 15/15 3.8it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361       0.81      0.798      0.809      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     99/100      3.28G      0.743      0.519      0.868        218        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.808      0.793      0.812       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    100/100      3.28G     0.7461     0.5183     0.8691        217        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.905      0.742      0.812       0.53\n",
      "\n",
      "100 epochs completed in 0.145 hours.\n",
      "Optimizer stripped from C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-color-train\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-color-train\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-color-train\\weights\\best.pt...\n",
      "Ultralytics 8.3.252  Python-3.12.0 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,007,403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.853      0.751      0.816      0.548\n",
      "                  Ball         13         13      0.813      0.231      0.334      0.173\n",
      "                  Hoop         17         17      0.863      0.882       0.88      0.627\n",
      "                Period         17         18      0.858      0.667      0.802      0.545\n",
      "                Player         24        188      0.888      0.814      0.896      0.564\n",
      "                   Ref         21         43      0.873      0.791       0.89      0.637\n",
      "            Shot Clock         14         14      0.773      0.972      0.966      0.604\n",
      "             Team Name          8         16      0.828      0.688      0.798      0.527\n",
      "           Team Points         17         35      0.907      0.832      0.896       0.66\n",
      "        Time Remaining         17         17      0.871      0.882       0.88      0.594\n",
      "Speed: 0.2ms preprocess, 1.8ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-color-train\u001b[0m\n",
      "Ultralytics 8.3.252  Python-3.12.0 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,007,403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 2.00.6 MB/s, size: 47.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\data\\basketball.yolov8-augmented\\color\\test\\labels.cache... 25 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 25/25  0.0s\n",
      "WARNING Box and segment counts should be equal, but got len(segments) = 15, len(boxes) = 391. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 2.0s/it 3.9s<12.0s\n",
      "                   all         25        391      0.893      0.762      0.825      0.514\n",
      "                  Ball         20         20      0.843       0.25      0.359      0.218\n",
      "                  Hoop         18         18      0.933      0.773      0.892      0.624\n",
      "                Period         19         19          1      0.774      0.971      0.554\n",
      "                Player         25        201      0.874      0.841      0.859      0.555\n",
      "                   Ref         22         47      0.771      0.787      0.769      0.478\n",
      "            Shot Clock         18         18      0.793      0.778      0.759      0.408\n",
      "             Team Name          6         12          1      0.873      0.925      0.623\n",
      "           Team Points         19         38      0.871      0.889      0.946      0.634\n",
      "        Time Remaining         18         18      0.955      0.889      0.949      0.533\n",
      "Speed: 4.6ms preprocess, 14.2ms inference, 0.0ms loss, 7.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-color-valid\u001b[0m\n",
      "Evaluation metrics for color augmented dataset: ultralytics.utils.metrics.DetMetrics object with attributes:\n",
      "\n",
      "ap_class_index: array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "box: ultralytics.utils.metrics.Metric object\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000022C1557E870>\n",
      "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
      "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,  0.00011708,  5.8538e-05,           0],\n",
      "       [          1,           1,           1, ...,   0.0027846,   0.0013923,           0],\n",
      "       [          1,           1,           1, ...,     0.51351,     0.51351,           0],\n",
      "       ...,\n",
      "       [          1,           1,           1, ...,     0.12766,     0.12766,           0],\n",
      "       [          1,           1,           1, ...,     0.27143,     0.27143,           0],\n",
      "       [          1,           1,           1, ...,     0.26471,     0.26471,           0]], shape=(9, 1000)), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.050228,    0.050228,    0.089183, ...,           0,           0,           0],\n",
      "       [    0.14286,     0.14286,     0.26798, ...,           0,           0,           0],\n",
      "       [    0.12298,     0.12298,     0.17745, ...,           0,           0,           0],\n",
      "       ...,\n",
      "       [    0.10084,     0.10084,     0.14579, ...,           0,           0,           0],\n",
      "       [    0.23899,     0.23899,     0.29664, ...,           0,           0,           0],\n",
      "       [    0.11215,     0.11215,     0.15028, ...,           0,           0,           0]], shape=(9, 1000)), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.026316,    0.026316,    0.048958, ...,           1,           1,           1],\n",
      "       [   0.077273,    0.077273,     0.15614, ...,           1,           1,           1],\n",
      "       [   0.065517,    0.065517,    0.097365, ...,           1,           1,           1],\n",
      "       ...,\n",
      "       [   0.053097,    0.053097,    0.078628, ...,           1,           1,           1],\n",
      "       [    0.13571,     0.13571,     0.17415, ...,           1,           1,           1],\n",
      "       [   0.059406,    0.059406,    0.081242, ...,           1,           1,           1]], shape=(9, 1000)), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[       0.55,        0.55,         0.5, ...,           0,           0,           0],\n",
      "       [    0.94444,     0.94444,     0.94444, ...,           0,           0,           0],\n",
      "       [          1,           1,           1, ...,           0,           0,           0],\n",
      "       ...,\n",
      "       [          1,           1,           1, ...,           0,           0,           0],\n",
      "       [          1,           1,           1, ...,           0,           0,           0],\n",
      "       [          1,           1,           1, ...,           0,           0,           0]], shape=(9, 1000)), 'Confidence', 'Recall']]\n",
      "fitness: np.float64(0.5140401647077255)\n",
      "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
      "maps: array([    0.21776,     0.62363,     0.55398,      0.5553,     0.47803,     0.40816,     0.62312,     0.63363,     0.53277])\n",
      "names: {0: 'Ball', 1: 'Hoop', 2: 'Period', 3: 'Player', 4: 'Ref', 5: 'Shot Clock', 6: 'Team Name', 7: 'Team Points', 8: 'Time Remaining'}\n",
      "nt_per_class: array([ 20,  18,  19, 201,  47,  18,  12,  38,  18])\n",
      "nt_per_image: array([20, 18, 19, 25, 22, 18,  6, 19, 18])\n",
      "results_dict: {'metrics/precision(B)': 0.893438773405915, 'metrics/recall(B)': 0.7616262729229606, 'metrics/mAP50(B)': 0.8254237822898745, 'metrics/mAP50-95(B)': 0.5140401647077255, 'fitness': 0.5140401647077255}\n",
      "save_dir: WindowsPath('C:/Users/kyana/Documents/GitHub/data-augmentation-detection-basketball/runs/augmented/yolov8n-color-valid')\n",
      "speed: {'preprocess': 4.6328120000544, 'inference': 14.171651999931782, 'loss': 0.00039999998989515007, 'postprocess': 7.045771999983117}\n",
      "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
      "task: 'detect'\n",
      "Training YOLOv8n on kernel augmented dataset...\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/basketball.yolov8-augmented/kernel/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n-kernel-train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=c:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-kernel-train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753067  ultralytics.nn.modules.head.Detect           [9, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,012,603 parameters, 3,012,587 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 43.828.7 MB/s, size: 75.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\data\\basketball.yolov8-augmented\\kernel\\train\\labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 240/240  0.0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 7.20.4 MB/s, size: 56.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\data\\basketball.yolov8-augmented\\kernel\\valid\\labels.cache... 25 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 25/25  0.0s\n",
      "Plotting labels to C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-kernel-train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-kernel-train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100      2.77G      1.765      4.152       1.35        269        640: 100% ━━━━━━━━━━━━ 15/15 2.5it/s 6.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
      "                   all         25        361     0.0145     0.0516     0.0114    0.00528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100      2.78G      1.704      2.605       1.23        382        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361     0.0234      0.128     0.0799     0.0447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100      2.79G      1.579       2.04      1.164        369        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.026      0.164     0.0901     0.0524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100      2.79G      1.506      1.842      1.159        412        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361     0.0366      0.221     0.0955     0.0574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100      2.79G      1.509      1.704      1.145        404        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.715      0.162        0.2      0.106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100      2.79G      1.465      1.659       1.13        386        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.781      0.195       0.22      0.128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100      2.79G      1.458      1.535      1.156        227        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
      "                   all         25        361      0.487      0.305      0.275      0.163\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100      2.79G      1.405      1.445      1.131        355        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.423      0.398      0.355      0.209\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100      2.79G       1.41      1.351      1.123        465        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.468       0.34      0.405      0.231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100      2.79G      1.364      1.275      1.099        329        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.466      0.377       0.47      0.276\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/100      2.79G      1.329      1.221      1.075        389        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.476      0.469      0.504        0.3\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/100      2.79G      1.333       1.19      1.073        263        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
      "                   all         25        361      0.599      0.487      0.536      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/100      2.79G      1.315      1.195      1.093        291        640: 100% ━━━━━━━━━━━━ 15/15 2.8it/s 5.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
      "                   all         25        361      0.609      0.504      0.524      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/100      2.79G      1.279      1.122      1.059        273        640: 100% ━━━━━━━━━━━━ 15/15 3.0it/s 5.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
      "                   all         25        361      0.648      0.552        0.6      0.363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/100      2.79G      1.269      1.091      1.046        292        640: 100% ━━━━━━━━━━━━ 15/15 3.0it/s 4.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
      "                   all         25        361      0.688      0.552      0.611      0.365\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/100      2.79G      1.275      1.077      1.058        282        640: 100% ━━━━━━━━━━━━ 15/15 3.0it/s 5.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
      "                   all         25        361       0.65      0.532      0.607      0.387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/100      2.79G      1.242      1.058      1.048        309        640: 100% ━━━━━━━━━━━━ 15/15 3.1it/s 4.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
      "                   all         25        361      0.752      0.507        0.6       0.37\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/100      2.79G      1.231      1.016      1.037        372        640: 100% ━━━━━━━━━━━━ 15/15 2.9it/s 5.2s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
      "                   all         25        361      0.656      0.567      0.631      0.372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/100      2.79G      1.225      1.036      1.027        325        640: 100% ━━━━━━━━━━━━ 15/15 3.1it/s 4.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
      "                   all         25        361      0.736      0.634      0.661       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/100      2.79G      1.203     0.9857       1.02        360        640: 100% ━━━━━━━━━━━━ 15/15 3.1it/s 4.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.627      0.633       0.67      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/100      2.79G      1.181     0.9731      1.033        404        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
      "                   all         25        361       0.64      0.654      0.674      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/100      2.79G      1.179     0.9601      1.021        392        640: 100% ━━━━━━━━━━━━ 15/15 3.1it/s 4.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.719      0.602      0.673      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/100      2.79G      1.167     0.9218      1.002        438        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.714      0.696      0.711      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/100      2.79G      1.195     0.9332      1.017        254        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.643      0.655      0.688      0.435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/100      2.79G      1.146     0.8985      1.005        265        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.716       0.63       0.72      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/100      2.79G       1.13     0.8719      0.995        255        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361      0.782      0.656      0.721      0.462\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/100      2.79G      1.162     0.8906      1.005        335        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.713       0.67      0.693      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/100      2.79G      1.138     0.8812      1.003        384        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.675      0.721      0.722      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/100      2.79G       1.15     0.9039     0.9967        272        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.783      0.682      0.732      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/100      2.79G      1.098     0.8451     0.9899        289        640: 100% ━━━━━━━━━━━━ 15/15 3.0it/s 5.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8it/s 0.3s\n",
      "                   all         25        361      0.706      0.701      0.727      0.457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/100      2.79G      1.081     0.8349     0.9797        366        640: 100% ━━━━━━━━━━━━ 15/15 3.0it/s 4.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.3s\n",
      "                   all         25        361      0.756      0.696       0.74      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/100      2.79G      1.111     0.8563     0.9888        351        640: 100% ━━━━━━━━━━━━ 15/15 3.1it/s 4.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
      "                   all         25        361      0.715      0.698      0.737      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/100      2.79G      1.096     0.8327      0.979        249        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361      0.708      0.709      0.759      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/100      2.95G      1.096     0.8274     0.9772        409        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.711      0.731      0.769      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/100      2.95G      1.056     0.8098     0.9734        307        640: 100% ━━━━━━━━━━━━ 15/15 3.0it/s 5.1s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.753      0.716      0.765      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/100      2.95G      1.083     0.8177     0.9795        394        640: 100% ━━━━━━━━━━━━ 15/15 3.1it/s 4.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.789       0.73      0.781      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/100      2.95G      1.081     0.8155     0.9758        324        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.682      0.718      0.759      0.434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/100      2.95G      1.056     0.7942     0.9765        231        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.747      0.758      0.792      0.487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/100      2.95G      1.084     0.8163       0.97        372        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.807      0.719      0.796      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/100      2.95G      1.083     0.7873     0.9677        322        640: 100% ━━━━━━━━━━━━ 15/15 2.6it/s 5.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
      "                   all         25        361      0.765      0.772      0.793      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/100      2.95G       1.06     0.7767     0.9728        352        640: 100% ━━━━━━━━━━━━ 15/15 3.1it/s 4.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.756       0.77      0.797       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/100      2.95G      1.048     0.7688     0.9682        253        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
      "                   all         25        361      0.774      0.741      0.796      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/100      2.95G      1.044     0.7585     0.9659        413        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
      "                   all         25        361      0.789      0.724      0.787      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     44/100      2.95G      1.029     0.7469     0.9589        343        640: 100% ━━━━━━━━━━━━ 15/15 3.1it/s 4.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
      "                   all         25        361      0.822      0.762      0.796      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     45/100      2.95G      1.037     0.7453     0.9521        398        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.825      0.783      0.816      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     46/100      2.95G     0.9973     0.7362     0.9462        260        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361      0.778      0.775      0.814      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     47/100      2.95G      1.004     0.7464     0.9573        417        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.789      0.777      0.789        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     48/100      2.95G      1.011     0.7318     0.9561        296        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.3s\n",
      "                   all         25        361      0.783      0.762      0.795      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     49/100      2.95G      1.008     0.7289     0.9521        351        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.776      0.689      0.778      0.493\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     50/100      2.95G      1.002      0.737     0.9501        387        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361      0.823      0.755       0.81       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     51/100      2.95G      1.018     0.7299      0.951        270        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8it/s 0.3s\n",
      "                   all         25        361      0.796      0.776      0.813      0.517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     52/100      2.95G     0.9962     0.7095     0.9354        353        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.867      0.747      0.798      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     53/100      2.95G      1.004     0.7114     0.9461        285        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361      0.861       0.75      0.803       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     54/100      2.95G     0.9934     0.6967     0.9466        368        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.829      0.756      0.801      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     55/100      2.95G     0.9705     0.6928     0.9368        401        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.1it/s 0.2s\n",
      "                   all         25        361      0.827      0.795      0.816      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     56/100      2.95G       1.01     0.6981     0.9327        365        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
      "                   all         25        361      0.852      0.785       0.82      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     57/100      2.95G     0.9754     0.6964     0.9418        382        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
      "                   all         25        361       0.82      0.767      0.823      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     58/100      2.95G     0.9696      0.686     0.9416        378        640: 100% ━━━━━━━━━━━━ 15/15 3.0it/s 5.0s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
      "                   all         25        361      0.759      0.803      0.827      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     59/100      2.95G     0.9683      0.687     0.9398        368        640: 100% ━━━━━━━━━━━━ 15/15 2.9it/s 5.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
      "                   all         25        361      0.816      0.779      0.817       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     60/100      2.95G     0.9459     0.6641     0.9291        330        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
      "                   all         25        361      0.808      0.769      0.794      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     61/100      2.95G     0.9351      0.671      0.933        319        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
      "                   all         25        361      0.785      0.806      0.799      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     62/100      2.95G     0.9487     0.6673     0.9345        244        640: 100% ━━━━━━━━━━━━ 15/15 3.1it/s 4.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.821      0.781      0.806      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     63/100      2.95G     0.9452     0.6677     0.9237        326        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.862      0.769      0.811      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     64/100      2.95G     0.9396     0.6683      0.934        241        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.816      0.758      0.818      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     65/100      2.95G     0.9344      0.658     0.9257        283        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361       0.84      0.779      0.822      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     66/100      2.95G     0.8947     0.6362     0.9164        350        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361      0.808      0.786      0.815      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     67/100      2.95G     0.9213     0.6392     0.9202        336        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361      0.837      0.786      0.808      0.516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     68/100      2.95G     0.9163     0.6358      0.921        278        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.812      0.798      0.809      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     69/100      2.95G     0.9028     0.6373     0.9309        282        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
      "                   all         25        361      0.818      0.776      0.811       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     70/100      2.95G     0.9107     0.6419     0.9293        298        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.824      0.782      0.807      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     71/100      2.95G     0.9204     0.6444     0.9153        287        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.842      0.789      0.806      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     72/100      2.95G     0.9455     0.6516     0.9228        338        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
      "                   all         25        361      0.856      0.816      0.826      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     73/100      2.95G     0.9001     0.6334     0.9253        327        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
      "                   all         25        361      0.857      0.806      0.821      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     74/100      2.95G     0.8919     0.6274      0.915        336        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.2it/s 0.2s\n",
      "                   all         25        361      0.805      0.817      0.818      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     75/100      2.95G     0.9026     0.6318     0.9099        189        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.837      0.791      0.813      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     76/100      2.95G     0.9159     0.6405     0.9204        475        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.848      0.805      0.821      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     77/100      2.95G     0.9081     0.6336     0.9187        386        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.848      0.804      0.826      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     78/100      2.95G     0.8919      0.621     0.9091        327        640: 100% ━━━━━━━━━━━━ 15/15 3.2it/s 4.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361       0.85      0.799      0.834      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     79/100      2.95G     0.8739      0.614     0.9126        248        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.1it/s 0.2s\n",
      "                   all         25        361      0.857      0.803      0.829      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     80/100      2.95G     0.8712     0.6042      0.905        465        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.3it/s 0.2s\n",
      "                   all         25        361      0.813      0.801      0.822      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     81/100      2.95G     0.8912     0.6183     0.9114        333        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.849       0.79      0.826      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     82/100      2.95G     0.8906     0.6218     0.9102        374        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
      "                   all         25        361      0.858      0.792      0.825      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     83/100      2.95G      0.884     0.6136     0.9139        266        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
      "                   all         25        361      0.868      0.786      0.828      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     84/100      2.95G      0.875     0.6051     0.9048        293        640: 100% ━━━━━━━━━━━━ 15/15 3.3it/s 4.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361       0.86      0.773      0.822      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     85/100      3.12G     0.8582     0.6012     0.9031        292        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
      "                   all         25        361      0.856      0.773      0.823      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     86/100      3.12G     0.8621     0.5984      0.913        256        640: 100% ━━━━━━━━━━━━ 15/15 3.5it/s 4.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
      "                   all         25        361      0.859      0.779      0.821      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     87/100      3.12G     0.8631     0.5998     0.9118        355        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.842      0.773      0.816      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     88/100      3.12G     0.8561     0.5877     0.9016        400        640: 100% ━━━━━━━━━━━━ 15/15 2.7it/s 5.6s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
      "                   all         25        361      0.829      0.783      0.813      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     89/100      3.28G     0.8493     0.5931     0.8984        450        640: 100% ━━━━━━━━━━━━ 15/15 2.6it/s 5.8s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
      "                   all         25        361      0.821      0.821      0.818      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     90/100      3.28G     0.8753     0.6055     0.9185        314        640: 100% ━━━━━━━━━━━━ 15/15 3.4it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361       0.84      0.801      0.818      0.541\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     91/100      3.28G      0.784     0.5518     0.8799        199        640: 100% ━━━━━━━━━━━━ 15/15 3.9it/s 3.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.828      0.808      0.824      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     92/100      3.28G     0.7771     0.5394     0.8724        241        640: 100% ━━━━━━━━━━━━ 15/15 3.8it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361      0.829      0.802      0.825      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     93/100      3.28G     0.7554      0.524      0.868        257        640: 100% ━━━━━━━━━━━━ 15/15 4.1it/s 3.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
      "                   all         25        361      0.829      0.802      0.827      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     94/100      3.28G     0.7606      0.531     0.8689        214        640: 100% ━━━━━━━━━━━━ 15/15 4.1it/s 3.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.1it/s 0.2s\n",
      "                   all         25        361      0.856      0.783      0.826       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     95/100      3.28G     0.7546     0.5288      0.868        230        640: 100% ━━━━━━━━━━━━ 15/15 4.0it/s 3.8s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.1it/s 0.2s\n",
      "                   all         25        361      0.855      0.805      0.825      0.538\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     96/100      3.28G     0.7548      0.524     0.8722        228        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.2it/s 0.2s\n",
      "                   all         25        361      0.884       0.79      0.826       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     97/100      3.28G     0.7396     0.5134     0.8632        212        640: 100% ━━━━━━━━━━━━ 15/15 3.8it/s 3.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.9it/s 0.2s\n",
      "                   all         25        361      0.876      0.791      0.825      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     98/100      3.28G     0.7546      0.527     0.8661        219        640: 100% ━━━━━━━━━━━━ 15/15 3.6it/s 4.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.8it/s 0.2s\n",
      "                   all         25        361      0.866      0.794      0.824      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     99/100      3.28G     0.7284     0.5124     0.8655        218        640: 100% ━━━━━━━━━━━━ 15/15 4.0it/s 3.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
      "                   all         25        361      0.867      0.792      0.824      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    100/100      3.28G     0.7384     0.5157     0.8671        217        640: 100% ━━━━━━━━━━━━ 15/15 3.7it/s 4.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
      "                   all         25        361      0.874      0.785      0.822      0.539\n",
      "\n",
      "100 epochs completed in 0.139 hours.\n",
      "Optimizer stripped from C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-kernel-train\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-kernel-train\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-kernel-train\\weights\\best.pt...\n",
      "Ultralytics 8.3.252  Python-3.12.0 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,007,403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.0it/s 0.2s\n",
      "                   all         25        361       0.84      0.779      0.822      0.548\n",
      "                  Ball         13         13          1      0.297       0.36      0.206\n",
      "                  Hoop         17         17      0.779      0.941      0.903       0.65\n",
      "                Period         17         18       0.92      0.638      0.878      0.575\n",
      "                Player         24        188      0.889       0.84      0.902      0.577\n",
      "                   Ref         21         43      0.819      0.767      0.848      0.595\n",
      "            Shot Clock         14         14      0.657          1      0.913      0.547\n",
      "             Team Name          8         16      0.795       0.73      0.812      0.532\n",
      "           Team Points         17         35      0.831      0.857      0.869      0.627\n",
      "        Time Remaining         17         17      0.866      0.941      0.915      0.623\n",
      "Speed: 0.2ms preprocess, 1.5ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-kernel-train\u001b[0m\n",
      "Ultralytics 8.3.252  Python-3.12.0 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,007,403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 3.00.9 MB/s, size: 47.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\data\\basketball.yolov8-augmented\\kernel\\test\\labels.cache... 25 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 25/25  0.0s\n",
      "WARNING Box and segment counts should be equal, but got len(segments) = 15, len(boxes) = 391. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.6s/it 3.2s9.7s\n",
      "                   all         25        391      0.845      0.796       0.83      0.522\n",
      "                  Ball         20         20      0.957       0.25      0.352      0.189\n",
      "                  Hoop         18         18      0.942      0.897      0.922      0.598\n",
      "                Period         19         19          1      0.776      0.977      0.572\n",
      "                Player         25        201      0.879      0.841      0.865      0.564\n",
      "                   Ref         22         47      0.804      0.787      0.775      0.503\n",
      "            Shot Clock         18         18      0.644      0.778      0.744      0.439\n",
      "             Team Name          6         12      0.851      0.917      0.934      0.634\n",
      "           Team Points         19         38      0.763      0.974      0.938      0.614\n",
      "        Time Remaining         18         18      0.761      0.944      0.965      0.587\n",
      "Speed: 3.4ms preprocess, 16.0ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\kyana\\Documents\\GitHub\\data-augmentation-detection-basketball\\runs\\augmented\\yolov8n-kernel-valid\u001b[0m\n",
      "Evaluation metrics for kernel augmented dataset: ultralytics.utils.metrics.DetMetrics object with attributes:\n",
      "\n",
      "ap_class_index: array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "box: ultralytics.utils.metrics.Metric object\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000022C15526870>\n",
      "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
      "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,  0.00013982,  6.9911e-05,           0],\n",
      "       [          1,           1,           1, ...,   0.0020908,   0.0010454,           0],\n",
      "       [          1,           1,           1, ...,     0.79167,     0.79167,           0],\n",
      "       ...,\n",
      "       [          1,           1,           1, ...,     0.23529,     0.23529,           0],\n",
      "       [          1,           1,           1, ...,     0.18095,     0.18095,           0],\n",
      "       [          1,           1,           1, ...,     0.66667,     0.66667,           0]], shape=(9, 1000)), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.059459,    0.059531,     0.10738, ...,           0,           0,           0],\n",
      "       [    0.10932,     0.10932,     0.20072, ...,           0,           0,           0],\n",
      "       [    0.12219,     0.12219,     0.17934, ...,           0,           0,           0],\n",
      "       ...,\n",
      "       [      0.096,       0.096,      0.1388, ...,           0,           0,           0],\n",
      "       [    0.19588,     0.19588,     0.25182, ...,           0,           0,           0],\n",
      "       [    0.10141,     0.10141,     0.14437, ...,           0,           0,           0]], shape=(9, 1000)), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.031429,    0.031469,    0.059499, ...,           1,           1,           1],\n",
      "       [    0.05802,     0.05802,     0.11229, ...,           1,           1,           1],\n",
      "       [   0.065068,    0.065068,    0.098502, ...,           1,           1,           1],\n",
      "       ...,\n",
      "       [    0.05042,     0.05042,    0.074577, ...,           1,           1,           1],\n",
      "       [    0.10857,     0.10857,     0.14405, ...,           1,           1,           1],\n",
      "       [   0.053412,    0.053412,    0.077801, ...,           1,           1,           1]], shape=(9, 1000)), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[       0.55,        0.55,        0.55, ...,           0,           0,           0],\n",
      "       [    0.94444,     0.94444,     0.94444, ...,           0,           0,           0],\n",
      "       [          1,           1,           1, ...,           0,           0,           0],\n",
      "       ...,\n",
      "       [          1,           1,           1, ...,           0,           0,           0],\n",
      "       [          1,           1,           1, ...,           0,           0,           0],\n",
      "       [          1,           1,           1, ...,           0,           0,           0]], shape=(9, 1000)), 'Confidence', 'Recall']]\n",
      "fitness: np.float64(0.5222886460026512)\n",
      "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
      "maps: array([    0.18947,     0.59813,     0.57174,     0.56385,     0.50263,     0.43881,     0.63431,     0.61435,     0.58731])\n",
      "names: {0: 'Ball', 1: 'Hoop', 2: 'Period', 3: 'Player', 4: 'Ref', 5: 'Shot Clock', 6: 'Team Name', 7: 'Team Points', 8: 'Time Remaining'}\n",
      "nt_per_class: array([ 20,  18,  19, 201,  47,  18,  12,  38,  18])\n",
      "nt_per_image: array([20, 18, 19, 25, 22, 18,  6, 19, 18])\n",
      "results_dict: {'metrics/precision(B)': 0.8445737261357371, 'metrics/recall(B)': 0.7959666472186633, 'metrics/mAP50(B)': 0.830225288766575, 'metrics/mAP50-95(B)': 0.5222886460026512, 'fitness': 0.5222886460026512}\n",
      "save_dir: WindowsPath('C:/Users/kyana/Documents/GitHub/data-augmentation-detection-basketball/runs/augmented/yolov8n-kernel-valid')\n",
      "speed: {'preprocess': 3.365828000023612, 'inference': 16.02768400000059, 'loss': 0.0003119999746559188, 'postprocess': 1.5156159999605734}\n",
      "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
      "task: 'detect'\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate on all augmented datasets and store metrics\n",
    "all_metrics = {}\n",
    "\n",
    "for dataset_name, yaml_path in AUG_YAML_PATHS.items():\n",
    "    metrics = train_and_evaluate(dataset_name, yaml_path)\n",
    "    all_metrics[dataset_name] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173d2ad2",
   "metadata": {},
   "source": [
    "## Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e459aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_global_metrics(metrics, dataset_name, output_csv):\n",
    "    results = metrics.results_dict\n",
    "    speed = metrics.speed\n",
    "\n",
    "    df = pd.DataFrame([{\n",
    "        \"Dataset\": dataset_name,\n",
    "        \"mAP50\": results['metrics/mAP50(B)'],\n",
    "        \"mAP50-95\": results['metrics/mAP50-95(B)'],\n",
    "        \"Precision\": results['metrics/precision(B)'],\n",
    "        \"Recall\": results['metrics/recall(B)'],\n",
    "        \"Fitness\": results['fitness'],\n",
    "        \"Preprocess_ms\": speed['preprocess'],\n",
    "        \"Inference_ms\": speed['inference'],\n",
    "        \"Postprocess_ms\": speed['postprocess'],\n",
    "    }])\n",
    "\n",
    "    Path(output_csv).parent.mkdir(exist_ok=True, parents=True)\n",
    "    df.to_csv(output_csv, mode=\"a\", header=not Path(output_csv).exists(), index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97e76065",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name, metrics in all_metrics.items():\n",
    "    df_global = save_global_metrics(\n",
    "        metrics,\n",
    "        dataset_name=dataset_name,\n",
    "        output_csv=RESULTS_DIR + \"augmented_metrics.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19290afc",
   "metadata": {},
   "source": [
    "## Visualize metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b1cec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.read_csv(RESULTS_DIR + \"augmented_metrics.csv\")\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6d85362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot mAP50 for each augmentation type\n",
    "metrics_df_sorted = metrics_df.sort_values(by=\"mAP50\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=metrics_df_sorted, x=\"Dataset\", y=\"mAP50\", palette=PALETTE, hue=\"Dataset\")\n",
    "for i, v in enumerate(metrics_df_sorted['mAP50']):\n",
    "    plt.text(i, v + 0.01, f\"{v:.5f}\", ha='center')\n",
    "plt.title('Effect of different augmentation types on mAP50')\n",
    "plt.xlabel('Augmentation Type')\n",
    "plt.ylabel('mAP50')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Save this figure to media directory\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=metrics_df_sorted, x=\"Dataset\", y=\"mAP50\", palette=PALETTE, hue=\"Dataset\")\n",
    "for i, v in enumerate(metrics_df_sorted['mAP50']):\n",
    "    plt.text(i, v + 0.01, f\"{v:.5f}\", ha='center')\n",
    "plt.title('Effect of different augmentation types on mAP50')\n",
    "plt.xlabel('Augmentation Type')\n",
    "plt.ylabel('mAP50')\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(f\"{MEDIA_DIR}03-augmentations-mAP50.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e44afd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot mAP50-95 for each augmentation type\n",
    "metrics_df_sorted = metrics_df.sort_values(by=\"mAP50-95\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=metrics_df_sorted, x=\"Dataset\", y=\"mAP50-95\", palette=PALETTE, hue=\"Dataset\")\n",
    "for i, v in enumerate(metrics_df_sorted['mAP50-95']):\n",
    "    plt.text(i, v + 0.01, f\"{v:.5f}\", ha='center')\n",
    "plt.title('Effect of different augmentation types on mAP50-95')\n",
    "plt.xlabel('Augmentation Type')\n",
    "plt.ylabel('mAP50-95')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Save this figure to media directory\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=metrics_df_sorted, x=\"Dataset\", y=\"mAP50-95\", palette=PALETTE, hue=\"Dataset\")\n",
    "for i, v in enumerate(metrics_df_sorted['mAP50-95']):\n",
    "    plt.text(i, v + 0.01, f\"{v:.5f}\", ha='center')\n",
    "plt.title('Effect of different augmentation types on mAP50-95')\n",
    "plt.xlabel('Augmentation Type')\n",
    "plt.ylabel('mAP50-95')\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(f\"{MEDIA_DIR}03-augmentations-mAP50-95.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d029338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Precision for each augmentation type\n",
    "metrics_df_sorted = metrics_df.sort_values(by=\"Precision\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=metrics_df_sorted, x=\"Dataset\", y=\"Precision\", palette=PALETTE, hue=\"Dataset\")\n",
    "for i, v in enumerate(metrics_df_sorted['Precision']):\n",
    "    plt.text(i, v + 0.01, f\"{v:.5f}\", ha='center')\n",
    "plt.title('Effect of different augmentation types on Precision')\n",
    "plt.xlabel('Augmentation Type')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Save this figure to media directory\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=metrics_df_sorted, x=\"Dataset\", y=\"Precision\", palette=PALETTE, hue=\"Dataset\")\n",
    "for i, v in enumerate(metrics_df_sorted['Precision']):\n",
    "    plt.text(i, v + 0.01, f\"{v:.5f}\", ha='center')\n",
    "plt.title('Effect of different augmentation types on Precision')\n",
    "plt.xlabel('Augmentation Type')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(f\"{MEDIA_DIR}03-augmentations-Precision.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "572dece9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Recall for each augmentation type\n",
    "metrics_df_sorted = metrics_df.sort_values(by=\"Recall\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=metrics_df_sorted, x=\"Dataset\", y=\"Recall\", palette=PALETTE, hue=\"Dataset\")\n",
    "for i, v in enumerate(metrics_df_sorted['Recall']):\n",
    "    plt.text(i, v + 0.01, f\"{v:.5f}\", ha='center')\n",
    "plt.title('Effect of different augmentation types on Recall')\n",
    "plt.xlabel('Augmentation Type')\n",
    "plt.ylabel('Recall')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Save this figure to media directory\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=metrics_df_sorted, x=\"Dataset\", y=\"Recall\", palette=PALETTE, hue=\"Dataset\")\n",
    "for i, v in enumerate(metrics_df_sorted['Recall']):\n",
    "    plt.text(i, v + 0.01, f\"{v:.5f}\", ha='center')\n",
    "plt.title('Effect of different augmentation types on Recall')\n",
    "plt.xlabel('Augmentation Type')\n",
    "plt.ylabel('Recall')\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(f\"{MEDIA_DIR}03-augmentations-Recall.png\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
